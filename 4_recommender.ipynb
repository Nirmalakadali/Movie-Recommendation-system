{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e1c5cfb-96b1-420a-8338-34acdc315ec7",
   "metadata": {},
   "source": [
    "## Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea82fb5c-b9dd-436b-968a-0d95e9652384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442c88aa-e53c-4038-b335-34177f772b65",
   "metadata": {},
   "source": [
    "## Functions Implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e527b388-67e1-46de-a3b6-21984a196b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def support(movies):\n",
    "    matching_users = [user for user in train_set if all(movie in train_set[user] for movie in movies)]\n",
    "    return len(matching_users) / len(train_set)\n",
    "def generate_frequent_itemsets(itemset_size, minsup,item_sets):\n",
    "    frequent_itemsets = []\n",
    "\n",
    "    if itemset_size == 2:\n",
    "        candidates = [(x, y) for x in l1_movies for y in l1_movies if x < y]\n",
    "    else:\n",
    "        candidates = []\n",
    "        candidate=[]\n",
    "        for i in range(len(item_sets)):\n",
    "            for j in range(i + 1, len(item_sets)):\n",
    "                if sorted(item_sets[i][:-1]) == sorted(item_sets[j][:-1]):\n",
    "                    candidate = list(item_sets[i][:-1])\n",
    "                    candidate.append( item_sets[i][-1])\n",
    "                    candidate.append(item_sets[j][-1])\n",
    "                    candidates.append(candidate)\n",
    "    for candidate in candidates:\n",
    "        sup = support(candidate)\n",
    "        if sup >= minsup:\n",
    "            frequent_itemsets.append(candidate)\n",
    "\n",
    "    return frequent_itemsets\n",
    "def generate_association_rules(item_list, minconf):\n",
    "\n",
    "    for x in item_list:\n",
    "        s = support(x)\n",
    "        for i in range(len(x)):\n",
    "            antecedent = [x[j] for j in range(len(x)) if j != i]\n",
    "            conf = s / support(antecedent)\n",
    "            if conf >= minconf:\n",
    "                ass_rules.append([antecedent, [x[i]], s, conf])\n",
    "    \n",
    "    return ass_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11c766c-cafd-44a5-893c-f8a1893ec904",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907e6e64-14f1-4a21-b102-36c0f60be2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ratings.csv')\n",
    "\n",
    "df = df[df['rating'] > 2]\n",
    "\n",
    "user_counts = df.groupby('userId')['movieId'].count()\n",
    "valid_users = user_counts[user_counts > 10].index\n",
    "df = df[df['userId'].isin(valid_users)]\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_set = {}\n",
    "test_set = {}\n",
    "\n",
    "for user, group in train_data.groupby('userId'):\n",
    "    train_set[user] = list(group['movieId'])\n",
    "\n",
    "for user, group in test_data.groupby('userId'):\n",
    "    test_set[user] = list(group['movieId'])\n",
    "\n",
    "movies_train = [movie for user in train_set for movie in train_set[user]]\n",
    "movies_train_unique = list(set(movies_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dab7993-609b-4475-85bb-859e346239d2",
   "metadata": {},
   "source": [
    "### Part-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9645c-83f0-4e08-ba7b-429cecec0b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "minsup = 0.09\n",
    "minconf = 0.1\n",
    "\n",
    "asr_movies_sup = {movie: support([movie]) for movie in movies_train_unique if support([movie]) >= minsup}\n",
    "\n",
    "movies_stminsup = list(asr_movies_sup.keys())\n",
    "\n",
    "l1_movies = movies_stminsup\n",
    "\n",
    "l2_movies = generate_frequent_itemsets(2, minsup,l1_movies)\n",
    "l3_movies = generate_frequent_itemsets(3, minsup,l2_movies)\n",
    "l4_movies = generate_frequent_itemsets(4, minsup,l3_movies)\n",
    "\n",
    "ass_rules = []\n",
    "\n",
    "\n",
    "generate_association_rules(l2_movies, minconf)\n",
    "generate_association_rules(l3_movies, minconf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcd213b-f61b-466b-a27b-5646f233e7f4",
   "metadata": {},
   "source": [
    "### Part-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18927b5-8222-4195-ab7b-bbd180d4824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_rules=sorted(ass_rules, key=lambda x: x[2], reverse=True)\n",
    "conf_rules=sorted(ass_rules, key=lambda x: x[3], reverse=True)\n",
    "\n",
    "top_100_sup_rules=sup_rules[:100]\n",
    "top_100_conf_rules=conf_rules[:100]\n",
    "\n",
    "common_sup_conf_rules=[]\n",
    "for x in top_100_conf_rules:\n",
    "  if x in top_100_sup_rules:\n",
    "    common_sup_conf_rules.append(x)\n",
    "print(common_sup_conf_rules)\n",
    "\n",
    "with open('10_top100RulesBySup.txt', 'w') as sup_file:\n",
    "    for rule in sup_rules:\n",
    "        sup_file.write(','.join(map(str, rule)) + '\\n')\n",
    "\n",
    "with open('4_top100RulesByConf', 'w') as conf_file:\n",
    "    for rule in conf_rules:\n",
    "        conf_file.write(','.join(map(str, rule)) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91998d17-a4d6-4838-8d18-df764f0c646d",
   "metadata": {},
   "source": [
    "### Part-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621190d3-390c-4608-a339-ad42cafad918",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_avgs=[]\n",
    "recall_avgs=[]\n",
    "for k in range(1,11):\n",
    "  for user in  train_set:\n",
    "    train = train_set[user]\n",
    "    if user in test_set:\n",
    "        test = test_set[user]\n",
    "        recall_sum=0\n",
    "        precision_sum=0\n",
    "        recommendation=[]\n",
    "        for x in train:\n",
    "          y=[]\n",
    "          count=0\n",
    "          for asr in conf_rules:\n",
    "            if(int(asr[0][0])==int(x)):\n",
    "              y = y+ asr[1]\n",
    "              count+=1\n",
    "              if(count==k):\n",
    "                break\n",
    "          recommendation = recommendation + y\n",
    "        hitset = []\n",
    "        for m in recommendation:\n",
    "          if m in test:\n",
    "            hitset.append(m)\n",
    "        recall = len(hitset)/len(test)\n",
    "        if(len(recommendation)==0):\n",
    "          precision=0\n",
    "        else:\n",
    "          precision = len(hitset)/len(recommendation)\n",
    "        recall_sum+=recall\n",
    "        precision_sum+=precision\n",
    "  recall_avg = recall_sum / len(train_set)\n",
    "  precision_avg = precision_sum / len(train_set)\n",
    "  precision_avgs.append(precision_avg)\n",
    "  recall_avgs.append(recall_avg)\n",
    "\n",
    "print(precision_avgs)\n",
    "print(recall_avgs)\n",
    "\n",
    "x=[i for i in range(1,11)]\n",
    "plt.plot(x,precision_avgs,label='precision')\n",
    "plt.plot(x,recall_avgs, label='recall')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edc5e6b-1965-44d2-b032-1ca71d37b9b4",
   "metadata": {},
   "source": [
    "Decreasing Precision: On increasing the number of rules (k), the average precision is likely to decrease. This is because with more rules, we are recommending a larger set of items, and some of those recommendations may not be relevant to the user. As a result, the precision, which measures how many of the recommended items are relevant, tends to decrease as k increases.\r\n",
    "\r\n",
    "Increasing Recall: On the other handOn increasing the number of rules (e) N, the average recall is likely to increase. This is because with more rulesweou are recommending a larger set of items, which is more likely to include some of the relevant items from the test set. Recall measures how many of the relevant items are included in the recommendations, and aweou provide more recommendationsweou are more likely to cover a larger portion of the relevant items.\r\n",
    "\r\n",
    "Trade-off Between Precision and Recall: The graph will likely show a trade-off between precision and recall. Wwe you have fewer rules (loker we you have a higher precision but a lower recall, and wwe you have more rules (higker we you have a higher recall but a lower precisces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f39be53-74af-4a34-a61b-1576675ca426",
   "metadata": {},
   "source": [
    "### Part-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ede7a-f143-4b27-90f6-228454864f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "sample_size = 20 \n",
    "sample_users = random.sample(list(test_set.keys()), sample_size)\n",
    "\n",
    "precision_avgs = []\n",
    "recall_avgs = []\n",
    "\n",
    "for k in range(1, 11):\n",
    "    recall_sum = 0\n",
    "    precision_sum = 0\n",
    "\n",
    "    for user in sample_users:\n",
    "        train = train_set[user]\n",
    "        if user in test_set:\n",
    "            test = test_set[user]\n",
    "            recommendation = []\n",
    "    \n",
    "            for x in train:\n",
    "                y = []\n",
    "                count = 0\n",
    "                for asr in conf_rules:\n",
    "                    if int(asr[0][0]) == int(x):\n",
    "                        y = y + asr[1]\n",
    "                        count += 1\n",
    "                        if count == k:\n",
    "                            break\n",
    "                recommendation = recommendation + y\n",
    "    \n",
    "            hit_set = [m for m in recommendation if m in test]\n",
    "    \n",
    "            recall = len(hit_set) / len(test)\n",
    "            precision = len(hit_set) / len(recommendation) if len(recommendation) > 0 else 0\n",
    "\n",
    "            recall_sum += recall\n",
    "            precision_sum += precision\n",
    "\n",
    "    recall_avg = recall_sum / sample_size\n",
    "    precision_avg = precision_sum / sample_size\n",
    "\n",
    "    precision_avgs.append(precision_avg)\n",
    "    recall_avgs.append(recall_avg)\n",
    "\n",
    "x = [i for i in range(1, 11)]\n",
    "plt.plot(x, precision_avgs, label='precision')\n",
    "plt.plot(x, recall_avgs, label='recall')\n",
    "plt.legend()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision and Recall vs. k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652603f6-30ee-482f-bc47-f41ed6f99b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_per_row = 5\n",
    "num_rows = (sample_size + users_per_row - 1) // users_per_row\n",
    "\n",
    "for row in range(num_rows):\n",
    "    plt.figure(figsize=(25, 5))\n",
    "\n",
    "    for col in range(users_per_row):\n",
    "        index = row * users_per_row + col\n",
    "        if index >= sample_size:\n",
    "            break\n",
    "\n",
    "        user = sample_users[index]\n",
    "        precision_avgs = []\n",
    "        recall_avgs = []\n",
    "\n",
    "        for k in range(1, 11):\n",
    "            train = train_set[user]\n",
    "            if user in test_set:\n",
    "                test = test_set[user]\n",
    "                recall_sum = 0\n",
    "                precision_sum = 0\n",
    "                recommendation = []\n",
    "    \n",
    "                for x in train:\n",
    "                    y = []\n",
    "                    count = 0\n",
    "                    for asr in conf_rules:\n",
    "                        if int(asr[0][0]) == int(x):\n",
    "                            y = y + asr[1]\n",
    "                            count += 1\n",
    "                            if count == k:\n",
    "                                break\n",
    "                    recommendation = recommendation + y\n",
    "    \n",
    "                hit_set = [m for m in recommendation if m in test]\n",
    "    \n",
    "                recall = len(hit_set) / len(test)\n",
    "                precision = len(hit_set) / len(recommendation) if len(recommendation) > 0 else 0\n",
    "    \n",
    "                recall_sum += recall\n",
    "                precision_sum += precision\n",
    "    \n",
    "            recall_avg = recall_sum\n",
    "            precision_avg = precision_sum\n",
    "\n",
    "            precision_avgs.append(precision_avg)\n",
    "            recall_avgs.append(recall_avg)\n",
    "\n",
    "        x = [i for i in range(1, 11)]\n",
    "        plt.subplot(1, users_per_row, col + 1)\n",
    "        plt.plot(x, precision_avgs, label='precision')\n",
    "        plt.plot(x, recall_avgs, label='recall')\n",
    "        plt.xlabel('k')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title(f'User {user}')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1252ca0f-1104-4ce9-8c89-a5fdde4ac011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a187506-c519-4297-b6a0-cef186936af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bffb021-201a-4d66-af53-410f2d6f31ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
